# ----------------------------------------------------------------------------------------
# -- Docs: https://github.com/cluster-apps-on-docker/spark-standalone-cluster-on-docker --
# ----------------------------------------------------------------------------------------
version: "3.6"
# volumes:
#   shared-workspace:
#     name: "hadoop-distributed-file-system"
#     driver: local

networks:
    localnet:
        attachable: true

services:
#  jupyterlab:
#    image: jupyterlab:3.0.0-spark-3.1.2
#
#    container_name: jupyterlab
#    ports:
#      - 8888:8888
#      - 4040:4040
#    volumes:
#      - ./workspace:/opt/workspace

  spark-master:
    image: spark-master:3.1.2
    # container_name: spark-master
    # environment:
      # - SPARK_DRIVER_MEMORY=16G
      # - SPARK_DRIVER_MAXRESULTSIZE=16G
      # - SPARK_DRIVER_MEMORY=512m
      # - SPARK_DRIVER_MAXRESULTSIZE=512m
    ports:
      - 8088:8080
      - 7077:7077
    volumes:
      - ./workspace:/opt/workspace
      - /home/cloud/dataset:/home/cloud/dataset
    networks:
      - localnet

  # spark-worker:
  #   image: spark-worker:3.1.2
  #   # container_name: spark-worker-1
  #   environment:
  #     - SPARK_WORKER_CORES=1
  #     - SPARK_WORKER_MEMORY=512m
  #     # - SPARK_WORKER_MEMORY=16G
  #     # - SPARK_EXECUTOR_MEMORY=16G
  #     # - SPARK_DRIVER_MEMORY=16G
  #     # - SPARK_DRIVER_MAXRESULTSIZE=16G
  #     - SPARK_MASTER_HOST=spark-master
  #     - SPARK_MASTER_PORT=7077
  #   extra_hosts:
  #     - "ecs-python2:10.50.0.194"
  #   ports:
  #    - 8081:8081
  #   volumes:
  #     - ./workspace:/opt/workspace
  #     - /home/cloud/dataset:/home/cloud/dataset
  #   # restart: unless-stopped
  #   deploy:
  #     replicas: 2
  #     # restart_policy: unless-stopped
  #   networks:
  #     - localnet
  #   # depends_on:
  #   #   - spark-master

